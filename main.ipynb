{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('datasets/train.csv')\n",
    "test_raw = pd.read_csv('datasets/test.csv')\n",
    "train_test = train_raw.append(test_raw, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test['Title'] = train_test['Name'].apply(lambda x: re.search('(\\w+)\\.', x).group(1))\n",
    "train_test['Title'].replace(['Don'], 'Mr', inplace=True)\n",
    "train_test['Title'].replace(['Mlle','Ms'], 'Miss', inplace=True)\n",
    "train_test['Title'].replace(['Mme', 'Lady', 'Dona'], 'Mrs', inplace=True)\n",
    "train_test['Title'].replace(['Countess', 'Jonkheer'], 'Noble', inplace=True)\n",
    "train_test['Title'].replace(['Capt', 'Col', 'Dr', 'Major', 'Sir'], 'Other', inplace=True)\n",
    "\n",
    "title_onehot = pd.get_dummies(train_test['Title'], prefix='Title')\n",
    "train_test = pd.concat([train_test, title_onehot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_onehot = pd.get_dummies(train_test['Sex'], prefix='Sex')\n",
    "train_test = pd.concat([train_test, sex_onehot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test['FamilySize'] = train_test['SibSp'] + train_test['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test['Embarked'].fillna(train_test['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "embarked_onehot = pd.get_dummies(train_test['Embarked'], prefix='Embarked')\n",
    "train_test = pd.concat([train_test, embarked_onehot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test['Cabin'].fillna('NO', inplace=True)\n",
    "train_test['Cabin'] = np.where(train_test['Cabin'] == 'NO', 'NO', 'YES')\n",
    "\n",
    "cabin_onehot = pd.get_dummies(train_test['Cabin'], prefix='Cabin')\n",
    "train_test = pd.concat([train_test, cabin_onehot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test['Fare'].fillna(train_test.groupby('Pclass')['Fare'].transform('mean'), inplace=True)\n",
    "\n",
    "shares = train_test.groupby('Ticket')['Fare'].transform('count')\n",
    "train_test['Fare'] = train_test['Fare'] / shares\n",
    "\n",
    "train_test.loc[train_test['Fare'] < 5, 'Fare'] = 0\n",
    "train_test.loc[(train_test['Fare'] >= 5) & (train_test['Fare'] < 10), 'Fare'] = 1\n",
    "train_test.loc[(train_test['Fare'] >= 10) & (train_test['Fare'] < 15), 'Fare'] = 2\n",
    "train_test.loc[(train_test['Fare'] >= 15) & (train_test['Fare'] < 30), 'Fare'] = 3\n",
    "train_test.loc[(train_test['Fare'] >= 30) & (train_test['Fare'] < 60), 'Fare'] = 4\n",
    "train_test.loc[(train_test['Fare'] >= 60) & (train_test['Fare'] < 100), 'Fare'] = 5\n",
    "train_test.loc[train_test['Fare'] >= 100, 'Fare'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test['GroupTicket'] = np.where(shares == 1, 'NO', 'YES')\n",
    "\n",
    "group_ticket_onehot = pd.get_dummies(train_test['GroupTicket'], prefix='GroupTicket')\n",
    "train_test = pd.concat([train_test, group_ticket_onehot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/base.py:485: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  linalg.lstsq(X, y)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "missing_age_df = pd.DataFrame(train_test[['Age', 'Parch', 'Sex', 'SibSp', 'FamilySize', 'Title', 'Fare', 'Pclass', 'Embarked']])\n",
    "missing_age_df = pd.get_dummies(missing_age_df,columns=['Title', 'FamilySize', 'Sex', 'Pclass' ,'Embarked'])\n",
    "missing_age_train = missing_age_df[missing_age_df['Age'].notnull()]\n",
    "missing_age_test = missing_age_df[missing_age_df['Age'].isnull()]\n",
    "\n",
    "def fill_missing_age(missing_age_train, missing_age_test):\n",
    "        missing_age_X_train = missing_age_train.drop(['Age'], axis=1)\n",
    "        missing_age_Y_train = missing_age_train['Age']\n",
    "        missing_age_X_test = missing_age_test.drop(['Age'], axis=1)\n",
    "        # 模型1\n",
    "        gbm_reg = GradientBoostingRegressor(n_estimators=100, max_depth=3, learning_rate=0.01, max_features=3, random_state=42)\n",
    "        gbm_reg.fit(missing_age_X_train, missing_age_Y_train)\n",
    "        missing_age_test['Age_GB'] = gbm_reg.predict(missing_age_X_test)\n",
    "        # 模型2\n",
    "        lrf_reg = LinearRegression(fit_intercept=True, normalize=True)\n",
    "        lrf_reg.fit(missing_age_X_train, missing_age_Y_train)\n",
    "        missing_age_test['Age_LRF'] = lrf_reg.predict(missing_age_X_test)\n",
    "        # 将两个模型预测后的均值作为最终预测结果\n",
    "        missing_age_test['Age'] = np.mean([missing_age_test['Age_GB'], missing_age_test['Age_LRF']])\n",
    "        return missing_age_test\n",
    "    \n",
    "train_test.loc[(train_test.Age.isnull()), 'Age'] = fill_missing_age(missing_age_train, missing_age_test)\n",
    "\n",
    "train_test.loc[train_test['Age'] < 9, 'Age'] = 0\n",
    "train_test.loc[(train_test['Age'] >= 9) & (train_test['Age'] < 18), 'Age'] = 1\n",
    "train_test.loc[(train_test['Age'] >= 18) & (train_test['Age'] < 27), 'Age'] = 2\n",
    "train_test.loc[(train_test['Age'] >= 27) & (train_test['Age'] < 36), 'Age'] = 3\n",
    "train_test.loc[(train_test['Age'] >= 36) & (train_test['Age'] < 45), 'Age'] = 4\n",
    "train_test.loc[(train_test['Age'] >= 45) & (train_test['Age'] < 54), 'Age'] = 5\n",
    "train_test.loc[(train_test['Age'] >= 54) & (train_test['Age'] < 63), 'Age'] = 6\n",
    "train_test.loc[(train_test['Age'] >= 63) & (train_test['Age'] < 72), 'Age'] = 7\n",
    "train_test.loc[(train_test['Age'] >= 72) & (train_test['Age'] < 81), 'Age'] = 8\n",
    "train_test.loc[train_test['Age'] >= 81, 'Age'] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengerId_test = train_test['PassengerId'][891:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Title', 'Sex', 'Embarked', 'Cabin', 'Ticket', 'GroupTicket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_test[:891]\n",
    "test = train_test[891:]\n",
    "X_train = train.drop(['Survived'], axis=1)\n",
    "y_train = train['Survived']\n",
    "X_test = test.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=13,\n",
       "            min_weig...    subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=None, voting='soft', weights=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=500, max_depth=5, min_samples_split=13)\n",
    "et = ExtraTreesClassifier(n_estimators=500, max_depth=7, min_samples_split=8)\n",
    "gbm = GradientBoostingClassifier(n_estimators=500, learning_rate=0.0135)\n",
    "voting = VotingClassifier(estimators=[('rf', rf), ('et', et), ('gbm', gbm)], voting='soft')\n",
    "voting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = voting.predict(X_test)\n",
    "submission = pd.DataFrame({'PassengerId': passengerId_test, 'Survived': y_predict.astype(np.int32)})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
